{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block 1: Package initialization\n",
    "Import required packages, do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import pytorch dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules.utils import _single, _pair, _triple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block 2: Useful classes\n",
    "Customized implementation of [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) and [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear), do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONV(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1,\n",
    "                 bias=False, padding_mode='zeros'):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = _pair(stride)\n",
    "        padding = _pair(padding)\n",
    "        dilation = _pair(dilation)\n",
    "        super(CONV, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, \n",
    "            groups, bias, padding_mode)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        # 'pytorch 2.0'\n",
    "        self.output = super().forward(input)\n",
    "        return self.output\n",
    "    \n",
    "class FC(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        super(FC, self).__init__(in_features, out_features, bias)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = F.linear(input, self.weight, self.bias)\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2\n",
    "\n",
    "### Code block 3: SimpleNN implementation\n",
    "\n",
    "Please follow the instructions in Lab 2(a) and fill in the code in the lines marked **Your code here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run on GPU...\n",
      "Forward pass successful\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Lab 2(a)\n",
    "Build the SimpleNN model by following Table 1\n",
    "\"\"\"\n",
    "\n",
    "# Create the neural network module: LeNet-5\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Layer definition\n",
    "        self.conv1 =     CONV(in_channels=3,out_channels=16,kernel_size=5,stride=1, padding=2)\n",
    "        self.conv2 =     CONV(in_channels=16,out_channels=16,kernel_size=3,stride=1,padding=2)\n",
    "        self.conv3 =     CONV(in_channels=16,out_channels=32,kernel_size=7,stride=1,padding=2)\n",
    "        self.fc1   =     FC(288,32)\n",
    "        self.fc2   =     FC(32,10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv 1\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        # MaxPool\n",
    "        x = F.max_pool2d(x, kernel_size=4,stride=2)\n",
    "        \n",
    "        # Conv 2\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        # MaxPool\n",
    "        x = F.max_pool2d(x, kernel_size=3,stride=2)\n",
    "        \n",
    "        # Conv 3\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        # MaxPool\n",
    "        x = F.max_pool2d(x, kernel_size=2,stride=2)\n",
    "        \n",
    "        # Flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # FC 1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # FC 2\n",
    "        out = F.relu(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# GPU check                \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device =='cuda':\n",
    "    print(\"Run on GPU...\")\n",
    "else:\n",
    "    print(\"Run on CPU...\")\n",
    "\n",
    "# Model Definition  \n",
    "net = SimpleNN()\n",
    "net = net.to(device)\n",
    "\n",
    "# Test forward pass\n",
    "data = torch.randn(5,3,32,32)\n",
    "data = data.to(device)\n",
    "# Forward pass \"data\" through \"net\" to get output \"out\" \n",
    "out =  net(data)   #Your code here\n",
    "\n",
    "# Check output shape\n",
    "assert(out.detach().cpu().numpy().shape == (5,10))\n",
    "print(\"Forward pass successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block 4: Shape observation\n",
    "Please follow the instructions in Lab 2(a) and fill in the code in the lines marked **Your code here**. Gather the printed results in Table 2 in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1      torch.Size([1, 3, 32, 32]) torch.Size([1, 16, 32, 32]) torch.Size([16, 3, 5, 5]) 1200       1228800   \n",
      "conv2      torch.Size([1, 16, 15, 15]) torch.Size([1, 16, 17, 17]) torch.Size([16, 16, 3, 3]) 2304       665856    \n",
      "conv3      torch.Size([1, 16, 8, 8]) torch.Size([1, 32, 6, 6]) torch.Size([32, 16, 7, 7]) 25088      903168    \n",
      "fc1        torch.Size([1, 288]) torch.Size([1, 32])  torch.Size([32, 288]) 9248       9216      \n",
      "fc2        torch.Size([1, 32])  torch.Size([1, 10])  torch.Size([10, 32]) 330        320       \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lab 2(b)\n",
    "\"\"\"\n",
    "# Forward pass of a single image\n",
    "data = torch.randn(1,3,32,32).to(device)\n",
    "# Forward pass \"data\" through \"net\" to get output \"out\" \n",
    "out =   net(data)  #Your code here\n",
    "\n",
    "# Iterate through all the CONV and FC layers of the model\n",
    "for name, module in net.named_modules():\n",
    "    if isinstance(module, CONV) or isinstance(module, FC):\n",
    "        # Get the input feature map of the module as a NumPy array\n",
    "        input =     module.input\n",
    "        # Get the output feature map of the module as a NumPy array\n",
    "        output =    module.output\n",
    "        # Get the weight of the module as a NumPy array\n",
    "        weight =      module.weight\n",
    "        # Compute the number of parameters in the weight\n",
    "        num_Param =     sum(p.numel() for p in module.parameters())\n",
    "        # Compute the number of MACs in the layer\n",
    "        num_MAC=3\n",
    "        if(isinstance(module,CONV)):\n",
    "            num_MAC = output.shape[0]*output.shape[1]*output.shape[2]*output.shape[3]*weight.shape[2]*weight.shape[3]*input.shape[1]\n",
    "        else:\n",
    "            num_MAC = output.shape[1]*input.shape[1]\n",
    "        \n",
    "        print(f'{name:10} {str(input.shape):20} {str(output.shape):20} {str(weight.shape):20} {str(num_Param):10} {str(num_MAC):10}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3 (Bonus)\n",
    "\n",
    "### Code block 5: Initial weight histogram\n",
    "Please follow the instructions in Lab 3(a) and fill in the code in the lines marked **Your code here**. Copy the output figures into your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lab 3(a)\n",
    "\"\"\"\n",
    "for name, module in net.named_modules():\n",
    "    if isinstance(module, CONV) or isinstance(module, FC):\n",
    "        # Get the weight of the module as a NumPy array\n",
    "        weight =  module.weight.detach()\n",
    "        weight = weight.to('cpu')\n",
    "        weight = weight.numpy()\n",
    "        \n",
    "        # Reshape for histogram\n",
    "        weight = weight.reshape(-1)\n",
    "        _ = plt.hist(weight, bins=20)\n",
    "        plt.title(\"Weight histogram of layer \"+name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block 6: Gradient histogram\n",
    "Please follow the instructions in Lab 3(b) and fill in the code in the lines marked **Your code here**. Copy the output figures into your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lab 3(b)\n",
    "'''\n",
    "# Loss definition\n",
    "criterion = nn.MSELoss()\n",
    "# Random target\n",
    "target = torch.randn(1, 10).to(device)\n",
    "\n",
    "# Loss computation\n",
    "loss =      #Your code here\n",
    "# Backward pass for gradients\n",
    "     #Your code here\n",
    "\n",
    "for name, module in net.named_modules():\n",
    "    if isinstance(module, CONV) or isinstance(module, FC):\n",
    "        # Get the gradient of the module as a NumPy array\n",
    "        gradient =      #Your code here\n",
    "        \n",
    "        # Reshape for histogram\n",
    "        gradient = gradient.reshape(-1)\n",
    "        _ = plt.hist(gradient, bins=20)\n",
    "        plt.title(\"Gradient histogram of layer \"+name)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block 7: Zero initialization?\n",
    "Please follow the instructions in Lab 3(c) and fill in the code in the lines marked **Your code here**. Copy the output figures into your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lab 3(c)\n",
    "'''\n",
    "# Set model weights to zero\n",
    "for name, module in net.named_modules():\n",
    "    if isinstance(module, CONV) or isinstance(module, FC):\n",
    "        # Set the weight of each module to all zero\n",
    "             #Your code here\n",
    "\n",
    "# Reset gradients\n",
    "net.zero_grad()\n",
    "        \n",
    "# Forward and backward pass\n",
    "# Random data and target\n",
    "data = torch.randn(1,3,32,32).to(device)\n",
    "target = torch.randn(1, 10).to(device)\n",
    "\n",
    "# Forward pass\n",
    "out =      #Your code here\n",
    "# Loss computation\n",
    "loss =      #Your code here\n",
    "# Backward pass\n",
    "     #Your code here\n",
    "\n",
    "for name, module in net.named_modules():\n",
    "    if isinstance(module, CONV) or isinstance(module, FC):\n",
    "        # Get the gradient of the module as a NumPy array\n",
    "        gradient =      #Your code here\n",
    "        \n",
    "        # Reshape for histogram\n",
    "        gradient = gradient.reshape(-1)\n",
    "        _ = plt.hist(gradient, bins=20)\n",
    "        plt.title(\"Gradient histogram of layer \"+name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
